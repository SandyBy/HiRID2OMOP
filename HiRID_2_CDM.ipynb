{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiRID conversion to OMOP CDM v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import sqlalchemy \n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UploadDB_Optimized:\n",
    "    \"\"\"\n",
    "    Functionality: In this class you can translate the whole hiRID into Postgresql, feel free to modify it according to your needs\\n\n",
    "    Variables:\\n\n",
    "    \\t*hirid_directory: Folder where your HiRID files uncompressed are located. Do not modify the file tree in order to work properly\\n\n",
    "    \\t*postgres_add: Connection string for the postgres database\\n\n",
    "    \\t*mapping_file: Directory path and file name for the Usagi's mapping folder, for more information about it check:\\nhttps://www.ohdsi.org/web/wiki/doku.php?id=documentation:software:usagi\\n \n",
    "    \\t*max_group: Default value 250. Given that HiRID is divided in 250 groups the max group is the number of groups you want to upload\\n\n",
    "    \\t*sampling_mode: Allows the user to insert only a percentage of the data\\n\n",
    "    Example:\\t\n",
    "    \\tuploadDb=UploadDB_Optimized('D:\\\\YourHiRIDFolderGoesHere\\\\',\"dbname='dbname' user='user' host='localhost' password='password' connect_timeout=1\",'D:\\\\DirectoryPath\\\\Vocabulary_translation.csv',1)\\n\n",
    "    \\tuploadDb.translate_upload()\n",
    "    \"\"\"\n",
    "    def __init__(self, hirid_directory, postgres_add, mapping_file,  max_group=250, sampling_mode=False):\n",
    "        #Simple variables\n",
    "        self.hirid_directory = hirid_directory\n",
    "        self.postgres_add = postgres_add\n",
    "        if(max_group>250):\n",
    "            max_group=250\n",
    "        elif(max_group<1):\n",
    "            max_group=1\n",
    "        self.max_group = max_group\n",
    "        self.person_upload_time=0\n",
    "        self.sampling_mode=sampling_mode\n",
    "        #Arrays &  Dictionaries\n",
    "        self.groups=np.arange(0,self.max_group)\n",
    "        self.pharma_lengths=np.array([])\n",
    "        self.measure_lengths=np.array([])\n",
    "        self.obs_period_lengths=np.array([])\n",
    "        self.visit_lengths=np.array([])\n",
    "        self.obs_lengths=np.array([])\n",
    "        #Dataframes\n",
    "        self.source_2_map=pd.read_csv(mapping_file, sep=',')\n",
    "        self.variableid_dict=self.source_2_map.set_index('source_code')['target_concept_id'].to_dict()\n",
    "        self.person_df=pd.DataFrame()\n",
    "        self.observations_df=pd.DataFrame()\n",
    "        self.pharmaceutic_df=pd.DataFrame()\n",
    "        self.person_visit_dict={}\n",
    "        #Statistics\n",
    "        self.local_initial_rows_obs=0\n",
    "        self.local_final_rows_obs=0\n",
    "        self.local_inital_rows_phr=0\n",
    "        self.local_final_rows_phr=0\n",
    "        self.global_initial_rows_obs=0\n",
    "        self.global_final_rows_obs=0\n",
    "        self.global_inital_rows_phr=0\n",
    "        self.global_final_rows_phr=0\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def translate_upload(self):\n",
    "        print('Beginning the translate and upload process...')\n",
    "        begin_time=datetime.datetime.now()\n",
    "        print('Process began at: '+str(begin_time))\n",
    "        global_start = time.process_time()\n",
    "        self.upload_person()\n",
    "        if(self.sampling_mode):\n",
    "            print('Translating in sample mode, expect less translated items')\n",
    "            pass\n",
    "        for i in self.groups:\n",
    "            group_start = time.process_time()\n",
    "            print('\\tTranslating item '+str(i+1) + ' of 250')\n",
    "            self.upload_observation_period(i)\n",
    "            self.upload_visit_occurrence(i)\n",
    "            self.upload_measurement(i)\n",
    "            self.global_initial_rows_obs+=self.local_initial_rows_obs\n",
    "            self.global_final_rows_obs+=self.local_final_rows_obs\n",
    "            \n",
    "            self.upload_pharmaceuticals(i)\n",
    "            self.global_inital_rows_phr+=self.local_inital_rows_phr\n",
    "            self.global_final_rows_phr+=self.local_final_rows_phr\n",
    "            print('\\tGroup #{:d} completed!'.format(i))\n",
    "            pass\n",
    "        end_time=datetime.datetime.now()\n",
    "        final_time=(end_time-begin_time).total_seconds()\n",
    "        print('Full Translation completed!')\n",
    "        print('{:d} of {:d} ({:.2%}) total observations translated'.format(self.global_final_rows_obs,\n",
    "                                                                               self.global_initial_rows_obs,\n",
    "                                                                              float(self.global_final_rows_obs)/float(self.global_initial_rows_obs)))\n",
    "        print('{:d} of {:d} ({:.2%}) drugs records translated'.format(self.global_final_rows_phr,\n",
    "                                                                          self.global_inital_rows_phr,\n",
    "                                                                         float(self.global_final_rows_phr)/float(self.global_inital_rows_phr)))\n",
    "        total_initial=self.global_initial_rows_obs+self.global_inital_rows_phr\n",
    "        total_final=self.global_final_rows_obs+self.global_final_rows_phr\n",
    "        print('{:d} of {:d} ({:.2%}) all the records were translated'.format(total_final,\n",
    "                                                                                 total_initial,\n",
    "                                                                                 float(total_final)/float(total_initial)))\n",
    "        print('Process ended at: '+str(datetime.datetime.now()))\n",
    "        pass\n",
    "    \n",
    "    def convert_df2sql(self,dataframe,table_name):\n",
    "        dataframe.to_csv(self.hirid_directory+table_name+'.csv',index=False)\n",
    "        conn = psycopg2.connect(self.postgres_add)\n",
    "        cur = conn.cursor()\n",
    "        with open('D:\\\\MIMICIII\\\\HiRID\\\\'+table_name+'.csv', 'r') as f:\n",
    "            # Notice that we don't need the `csv` module.\n",
    "            next(f) # Skip the header row.\n",
    "            cur.copy_from(f, table_name, sep=',',null='')\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        pass\n",
    "    \n",
    "    def transform_float(self,x):\n",
    "        try:\n",
    "            if (isinstance(x, str)):\n",
    "                return float(re.findall(r'\\d+', x)[0])\n",
    "            else:\n",
    "                return float(x)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(x)\n",
    "            return(np.nan)\n",
    "        pass\n",
    "    \n",
    "    def transform_float_min(self,x):\n",
    "        try:\n",
    "            if (isinstance(x, str)):\n",
    "                return float(re.findall(r'\\d+', x)[0])\n",
    "            else:\n",
    "                return float(x)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(x)\n",
    "            return(np.nan)\n",
    "        pass\n",
    "    \n",
    "    def upload_measurement(self,group_number):\n",
    "        print('\\t\\tUploading measurements for group #{:d}'.format(group_number))\n",
    "        obs2measurement=self.observations_df.copy()\n",
    "        self.local_initial_rows_obs=obs2measurement.shape[0]\n",
    "        obs2measurement['measurement_concept_id']=obs2measurement['variableid'].map(self.variableid_dict)\n",
    "        obs2measurement[obs2measurement[['measurement_concept_id']].isnull().any(axis=1)][['variableid']].count().values\n",
    "        obs2measurement.rename(columns={'patientid': 'person_id'})\n",
    "        obs2measurement[obs2measurement[['measurement_concept_id']].isnull().any(axis=1)][['variableid']].drop_duplicates()\n",
    "        obs2measurement=obs2measurement[obs2measurement.measurement_concept_id.notna()]\n",
    "        obs2measurement['measurement_concept_id']=obs2measurement.measurement_concept_id.astype(int)\n",
    "        obs2measurement['measurement_datetime']=pd.to_datetime(obs2measurement['datetime'], dayfirst=True)\n",
    "        obs2measurement['measurement_date']=pd.to_datetime(obs2measurement['datetime']).dt.date\n",
    "        obs2measurement['measurement_time']=pd.to_datetime(obs2measurement['datetime']).dt.time\n",
    "        obs2measurement['measurement_type_concept_id']=42530833 #LOINC: Laboratory\n",
    "        obs2measurement['value_as_number']=obs2measurement.value\n",
    "        obs2measurement['unit_source_value']=obs2measurement.status\n",
    "        obs2measurement['measurement_source_concept_id']=obs2measurement.type\n",
    "        obs2measurement['value_source_value']=obs2measurement.value\n",
    "        obs2measurement = obs2measurement[obs2measurement.stringvalue != '!folgt']\n",
    "        obs2measurement = obs2measurement[obs2measurement.stringvalue != '!fehlt']\n",
    "        obs2measurement = obs2measurement[obs2measurement.stringvalue != '!folgt mmol/L']\n",
    "        obs2measurement = obs2measurement[obs2measurement.stringvalue != 'mmol/L']\n",
    "        obs2measurement = obs2measurement[obs2measurement.stringvalue != '---']\n",
    "        obs2measurement = obs2measurement[obs2measurement.stringvalue != 'N']\n",
    "        obs2measurement['range_low'] = [self.transform_float_min(x.replace('<','')) if str(x).find('<') != -1 else np.nan for x in obs2measurement['stringvalue']]\n",
    "        obs2measurement['range_high'] = [self.transform_float(x) if (str(x).find('<') != 0 and x is not np.nan) else np.nan for x in obs2measurement['stringvalue']]\n",
    "        obs2measurement.value_as_concept_id=0\n",
    "        obs2measurement.loc[obs2measurement['status']==1, 'value_as_concept_id'] = 45878591 #LOINC: out of range\n",
    "        obs2measurement.loc[obs2measurement['status']==64, 'value_as_concept_id'] = 45880425 #LOINC: Greatly\n",
    "        obs2measurement.loc[obs2measurement['status']==32, 'value_as_concept_id'] = 36309396 #LOINC: Not Measured \n",
    "        obs2measurement.person_id=obs2measurement.patientid\n",
    "        obs2measurement['visit_occurrence_id']=obs2measurement['patientid'].map(self.person_visit_dict)\n",
    "        #passing the data\n",
    "        obs2measurement['person_id']=obs2measurement.patientid\n",
    "        obs2measurement['measurement_id'] = np.arange(len(obs2measurement))+(self.measure_lengths.sum()+1) #np.arange(len(obs2measurement))+1\n",
    "        self.measure_lengths=np.append(self.measure_lengths,self.observations_df.shape[0])\n",
    "        obs2measurement['operator_concept_id'] = np.nan\n",
    "        obs2measurement['unit_concept_id'] = np.nan\n",
    "        obs2measurement['provider_id'] = np.nan\n",
    "        obs2measurement['visit_detail_id'] = np.nan\n",
    "        obs2measurement['measurement_source_value'] = obs2measurement.value_as_number\n",
    "        obs2measurement['measurement_source_concept_id'] = obs2measurement.variableid\n",
    "        obs2measurement['measurement_time'] = obs2measurement.measurement_time.astype(str)\n",
    "        obs2measurement['measurement_time'] = obs2measurement['measurement_time'].str.slice(0,8)\n",
    "        obs2measurement=obs2measurement[['measurement_id','person_id','measurement_concept_id','measurement_date',\n",
    "                            'measurement_datetime','measurement_time','measurement_type_concept_id',\n",
    "                           'operator_concept_id','value_as_number','value_as_concept_id','unit_concept_id',\n",
    "                            'range_low','range_high','provider_id','visit_occurrence_id','visit_detail_id',\n",
    "                            'measurement_source_value','measurement_source_concept_id','unit_source_value',\n",
    "                            'value_source_value'\n",
    "                           ]]\n",
    "        obs2measurement['measurement_id']=obs2measurement['measurement_id'].astype(int)\n",
    "        obs2measurement['person_id']=obs2measurement['person_id'].astype(int)\n",
    "        obs2measurement['visit_occurrence_id']=obs2measurement['visit_occurrence_id'].astype(int)\n",
    "        if(self.sampling_mode):\n",
    "            obs2measurement=obs2measurement.sample(frac=0.01, replace=False)\n",
    "            pass\n",
    "            \n",
    "        self.convert_df2sql(obs2measurement, 'measurement')\n",
    "        self.local_final_rows_obs=obs2measurement.shape[0]\n",
    "        \n",
    "        print('\\t\\tMeasurement #{:d} done!'.format(group_number))\n",
    "        print('\\t\\t{:d} of {:d} ({:.2%}) observations translated'.format(self.local_final_rows_obs,\n",
    "                                                                         self.local_initial_rows_obs,\n",
    "                                                               float(self.local_final_rows_obs)/float(self.local_initial_rows_obs)))\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def upload_pharmaceuticals(self, group_number):\n",
    "        print('\\t\\tUploading visit pharmaceuticals for group #{:d}'.format(group_number))\n",
    "        self.pharmaceutic_df=pd.read_csv(self.hirid_directory+'raw_stage\\\\pharma_records\\\\csv\\\\part-'+str(group_number)+'.csv')\n",
    "        pharma_2_drug=self.pharmaceutic_df.copy()\n",
    "        self.local_inital_rows_phr=pharma_2_drug.shape[0]\n",
    "        pharma_2_drug['drug_exposure_id'] = np.arange(len(pharma_2_drug))+(self.pharma_lengths.sum()+1)\n",
    "        self.pharma_lengths=np.append(self.pharma_lengths,self.pharmaceutic_df.shape[0])\n",
    "        pharma_2_drug['person_id']=pharma_2_drug['patientid']\n",
    "        pharma_2_drug['drug_exposure_start_datetime']=pd.to_datetime(pharma_2_drug['givenat'], dayfirst=True)\n",
    "        pharma_2_drug['drug_exposure_start_date']=pd.to_datetime(pharma_2_drug['drug_exposure_start_datetime']).dt.date\n",
    "        pharma_2_drug['drug_exposure_end_datetime']=pd.to_datetime(pharma_2_drug['enteredentryat'], dayfirst=True)\n",
    "        pharma_2_drug['drug_exposure_end_datetime']=np.where(pharma_2_drug['drug_exposure_end_datetime']>pharma_2_drug['drug_exposure_start_datetime'],pharma_2_drug['drug_exposure_end_datetime'],pharma_2_drug['drug_exposure_start_datetime'])\n",
    "        pharma_2_drug['drug_exposure_end_date']=pd.to_datetime(pharma_2_drug['drug_exposure_end_datetime']).dt.date\n",
    "        pharma_2_drug['verbatim_end_date']=pd.to_datetime(pharma_2_drug['drug_exposure_end_datetime']).dt.date\n",
    "        pharma_2_drug['drug_type_concept_id']=38000180\n",
    "        pharma_2_drug['stop_reason']=0\n",
    "        pharma_2_drug['visit_occurrence_id']=pharma_2_drug['patientid'].map(self.person_visit_dict)\n",
    "        pharma_2_drug['quantity']=pharma_2_drug['givendose']\n",
    "        pharma_2_drug['days_supply']=0\n",
    "        pharma_2_drug['sig']=0\n",
    "        pharma_2_drug['lot_number']=np.nan\n",
    "        pharma_2_drug['provider_id']=np.nan\n",
    "        pharma_2_drug['visit_detail_id']=np.nan\n",
    "        pharma_2_drug['drug_source_value']=pharma_2_drug['pharmaid']\n",
    "        pharma_2_drug['drug_source_concept_id']=pharma_2_drug['typeid']\n",
    "        pharma_2_drug['route_source_value']=pharma_2_drug['route']\n",
    "        pharma_2_drug['dose_unit_source_value']=pharma_2_drug['doseunit']\n",
    "        pharma_2_drug['drug_concept_id']=pharma_2_drug['pharmaid'].map(self.variableid_dict)\n",
    "        pharma_2_drug['route_concept_id']=0\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='iv-inf', 'route_concept_id'] = 45884925 #LOINC: Infusion\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='iv-inj', 'route_concept_id'] = 45877627 #LOINC: Injection Intravenous\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='SC-inj', 'route_concept_id'] = 45882083 #LOINC: Injection, subcutaneous\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='SC-inj', 'route_concept_id'] = 45882083 #LOINC: Injection, subcutaneous\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='inhal', 'route_concept_id'] = 45880877 #LOINC: Inhalation\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='ep-inj', 'route_concept_id'] = 45877638 #LOINC: Injection, epidural\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='transcutan', 'route_concept_id'] = 45877646 #LOINC: Transdermal\n",
    "        pharma_2_drug.loc[pharma_2_drug['route']=='paravert', 'route_concept_id'] = 4170267 #LOINC: Paravertebral route\n",
    "        pharma_2_drug['refills'] = pharma_2_drug.groupby(['route_concept_id', 'infusionid']).cumcount()\n",
    "        pharma_2_drug = pharma_2_drug[pharma_2_drug['drug_concept_id'].notna()]\n",
    "        pharma_2_drug=pharma_2_drug[['drug_exposure_id','person_id','drug_concept_id','drug_exposure_start_date',\n",
    "                            'drug_exposure_start_datetime','drug_exposure_end_date','drug_exposure_end_datetime',\n",
    "                           'verbatim_end_date','drug_type_concept_id','stop_reason','refills',\n",
    "                            'quantity','days_supply','sig','route_concept_id','lot_number',\n",
    "                            'provider_id','visit_occurrence_id','visit_detail_id',\n",
    "                            'drug_source_value','drug_source_concept_id','route_source_value','dose_unit_source_value'\n",
    "                           ]]\n",
    "        pharma_2_drug['drug_exposure_id']=pharma_2_drug['drug_exposure_id'].astype(int)\n",
    "        pharma_2_drug['person_id']=pharma_2_drug['person_id'].astype(int)\n",
    "        pharma_2_drug['visit_occurrence_id']=pharma_2_drug['visit_occurrence_id'].astype(int)\n",
    "        pharma_2_drug['drug_concept_id']=pharma_2_drug['drug_concept_id'].astype(float).astype(int)\n",
    "        if(self.sampling_mode):\n",
    "            pharma_2_drug=pharma_2_drug.sample(frac=0.1, replace=False)\n",
    "            pass\n",
    "        self.convert_df2sql(pharma_2_drug, 'drug_exposure')\n",
    "        self.local_final_rows_phr=pharma_2_drug.shape[0]\n",
    "        print('\\t\\tPharmaceuticals #{:d} done!'.format(group_number))\n",
    "        print('\\t\\t{:d} of {:d} ({:.2%}) drugs records translated'.format(self.local_final_rows_phr,\n",
    "                                                                          self.local_inital_rows_phr,\n",
    "                                                                         float(self.local_final_rows_phr)/float(self.local_inital_rows_phr)))\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def upload_observation_period(self,group_number):\n",
    "        print('\\t\\tUploading observational period for group #{:d}'.format(group_number))\n",
    "        self.observations_df=pd.read_csv(self.hirid_directory+'raw_stage\\\\observation_tables\\\\csv\\\\part-'+str(group_number)+'.csv')\n",
    "        self.pharmaceutic_df=pd.read_csv(self.hirid_directory+'raw_stage\\\\pharma_records\\\\csv\\\\part-'+str(group_number)+'.csv')\n",
    "        \n",
    "        #Creating a table for maximum and min dates for the observations\n",
    "        patient_reg_dates=self.observations_df.copy()\n",
    "        patient_reg_dates['max_entertime']=pd.to_datetime(patient_reg_dates.groupby(['patientid'])['entertime'].transform('max'))\n",
    "        patient_reg_dates['max_datetime']=pd.to_datetime(patient_reg_dates.groupby(['patientid'])['datetime'].transform('max'))\n",
    "        patient_reg_dates['min_entertime']=pd.to_datetime(patient_reg_dates.groupby(['patientid'])['entertime'].transform('min'))\n",
    "        patient_reg_dates['min_datetime']=pd.to_datetime(patient_reg_dates.groupby(['patientid'])['datetime'].transform('min'))\n",
    "        patient_reg_dates=patient_reg_dates[['patientid','max_entertime','max_datetime','min_entertime','min_datetime']].drop_duplicates()\n",
    "        patient_reg_dates['max_time_obs']=np.where(patient_reg_dates['max_entertime']>patient_reg_dates['max_datetime'],patient_reg_dates['max_entertime'],patient_reg_dates['max_datetime'])\n",
    "        patient_reg_dates['min_time_obs']=np.where(patient_reg_dates['min_entertime']<patient_reg_dates['min_datetime'],patient_reg_dates['min_entertime'],patient_reg_dates['min_datetime'])\n",
    "        patient_reg_dates=patient_reg_dates[['patientid','max_time_obs','min_time_obs']]\n",
    "        \n",
    "        \n",
    "        #Creating a table for maximum and min dates for the pharmaceutical records\n",
    "        patient_reg_dates_phr=self.pharmaceutic_df.copy()\n",
    "        patient_reg_dates_phr['max_givenat']=pd.to_datetime(patient_reg_dates_phr.groupby(['patientid'])['givenat'].transform('max'))\n",
    "        patient_reg_dates_phr['max_enteredentryat']=pd.to_datetime(patient_reg_dates_phr.groupby(['patientid'])['enteredentryat'].transform('max'))\n",
    "        patient_reg_dates_phr['min_givenat']=pd.to_datetime(patient_reg_dates_phr.groupby(['patientid'])['givenat'].transform('min'))\n",
    "        patient_reg_dates_phr['min_enteredentryat']=pd.to_datetime(patient_reg_dates_phr.groupby(['patientid'])['enteredentryat'].transform('min'))\n",
    "        patient_reg_dates_phr=patient_reg_dates_phr[['patientid','max_givenat','max_enteredentryat','min_givenat','min_enteredentryat']].drop_duplicates()\n",
    "        patient_reg_dates_phr['max_time_phr']=np.where(patient_reg_dates_phr['max_givenat']>patient_reg_dates_phr['max_enteredentryat'],patient_reg_dates_phr['max_givenat'],patient_reg_dates_phr['max_enteredentryat'])\n",
    "        patient_reg_dates_phr['min_time_phr']=np.where(patient_reg_dates_phr['min_givenat']<patient_reg_dates_phr['min_enteredentryat'],patient_reg_dates_phr['min_givenat'],patient_reg_dates_phr['min_enteredentryat'])\n",
    "        patient_reg_dates_phr=patient_reg_dates_phr[['patientid','max_time_phr','min_time_phr']]\n",
    "        #Merging both tables\n",
    "        patient_dates=patient_reg_dates.copy()\n",
    "        patient_dates=patient_dates.join(patient_reg_dates_phr.set_index('patientid'), on='patientid')\n",
    "        patient_dates['max_time']=np.where(patient_dates['max_time_obs']>patient_dates['max_time_phr'],patient_dates['max_time_obs'],patient_dates['max_time_phr'])\n",
    "        patient_dates['min_time']=np.where(patient_dates['min_time_obs']<patient_dates['min_time_phr'],patient_dates['min_time_obs'],patient_dates['min_time_obs'])\n",
    "        patient_dates=patient_dates[['patientid','max_time','min_time']]\n",
    "        #Using date of admission\n",
    "        patient_adm=self.person_df.copy()\n",
    "        patient_adm=patient_adm['patientid','admissiontime']\n",
    "        patient_dates=patient_dates.join(patient_adm.set_index('patientid'), on='patientid')\n",
    "        patient_dates['min_time']=np.where(patient_dates['min_time']<patient_dates['admissiontime'],patient_dates['min_time'],patient_dates['admissiontime'])\n",
    "        patient_dates=patient_dates[['patientid','max_time','min_time']]\n",
    "        \n",
    "        obs_period=patient_dates.copy()\n",
    "        obs_period['observation_period_start_date']= pd.to_datetime(obs_period['max_time']).dt.date\n",
    "        obs_period['observation_period_end_date']= pd.to_datetime(obs_period['min_time']).dt.date\n",
    "        obs_period = obs_period.rename(columns={'patientid': 'person_id'})\n",
    "        obs_period['observation_period_id']=0\n",
    "        obs_period['period_type_concept_id']=44814724 # Obs Period Type: Period covering healthcare encounters\n",
    "        obs_period=obs_period[['observation_period_id','person_id','observation_period_start_date',\n",
    "                               'observation_period_end_date','period_type_concept_id']]\n",
    "        obs_period=obs_period.drop_duplicates()\n",
    "        obs_period['observation_period_id']= np.arange(len(obs_period))+(self.obs_period_lengths.sum()+1)\n",
    "        obs_period['observation_period_id'] = obs_period['observation_period_id'].astype(int)\n",
    "        self.obs_period_lengths=np.append(self.obs_period_lengths,obs_period.shape[0])\n",
    "        self.convert_df2sql(obs_period, 'observation_period')\n",
    "        print('\\t\\tObservational period #{:d} done!'.format(group_number))\n",
    "        pass\n",
    "    \n",
    "    def upload_visit_occurrence(self, group_number):\n",
    "        print('\\t\\tUploading visit occurrence for group #{:d}'.format(group_number))\n",
    "        self.observasations_df=pd.read_csv(self.hirid_directory+'raw_stage\\\\observation_tables\\\\csv\\\\part-'+str(group_number)+'.csv')\n",
    "        \n",
    "        visit_obs=self.observations_df.copy()\n",
    "        visit_obs['visit_start_datetime']=visit_obs.groupby(['patientid'])['datetime'].transform('min')\n",
    "        visit_obs['visit_end_datetime']=visit_obs.groupby(['patientid'])['entertime'].transform('max')\n",
    "        visit_obs['visit_start_date']= visit_obs['visit_start_datetime']\n",
    "        visit_obs['visit_end_date']= visit_obs['visit_end_datetime']\n",
    "        visit_obs['visit_type_concept_id']=32037 # Vocabulary Visit: Intensive Care\n",
    "        visit_obs['provider_id']=np.nan\n",
    "        visit_obs['care_site_id']=np.nan\n",
    "        visit_obs['visit_source_value']=0\n",
    "        visit_obs['visit_source_concept_id']=0\n",
    "        visit_obs['admitted_from_concept_id']=32199 # Vocabulary Visit: Information not available\n",
    "        visit_obs['discharge_to_concept_id']=0\n",
    "        visit_obs['discharge_to_source_value']=0\n",
    "        visit_obs=visit_obs.drop_duplicates()\n",
    "        visit_obs = visit_obs.rename(columns={'patientid': 'person_id'})\n",
    "        visit_obs['admitted_from_source_value']=0\n",
    "        visit_obs['preceding_visit_occurrence_id']=np.nan\n",
    "        visit_obs['visit_concept_id']=32037 # Vocabulary Visit: Intensive Care\n",
    "        visit_obs['visit_occurrence_id'] = 0\n",
    "        visit_obs=visit_obs[['visit_occurrence_id','person_id','visit_concept_id','visit_start_date',\n",
    "                             'visit_start_datetime','visit_end_date','visit_end_datetime','visit_type_concept_id',\n",
    "                            'provider_id','care_site_id','visit_source_value','visit_source_concept_id',\n",
    "                            'admitted_from_concept_id','admitted_from_source_value','discharge_to_source_value',\n",
    "                            'discharge_to_concept_id','preceding_visit_occurrence_id']]\n",
    "        visit_obs=visit_obs.drop_duplicates()\n",
    "        visit_obs['visit_occurrence_id'] = np.arange(len(visit_obs))+(self.visit_lengths.sum()+1)\n",
    "        visit_obs['visit_occurrence_id'] = visit_obs['visit_occurrence_id'].astype(int)\n",
    "        self.visit_lengths=np.append(self.visit_lengths,visit_obs.shape[0])\n",
    "        self.convert_df2sql(visit_obs, 'visit_occurrence')\n",
    "        self.person_visit_dict=visit_obs.set_index('person_id')['visit_occurrence_id'].to_dict()\n",
    "        print('\\t\\tVisit occurrence #{:d} done!'.format(group_number))\n",
    "        pass\n",
    "    \n",
    "    def upload_person(self,full_court=True):\n",
    "        print('\\tTranslating and uploading Person table')\n",
    "        start = time.process_time()\n",
    "        patient=pd.read_csv(self.hirid_directory+'general_table.csv')\n",
    "        patient['person_id']=patient.patientid.astype(int)\n",
    "        patient['gender_concept_id']=np.where(patient['sex']=='F', 8532 , 8507)\n",
    "        patient['admission_date']=pd.to_datetime(patient['admissiontime'], dayfirst=True)\n",
    "        patient['birth_datetime'] = patient['admission_date'] -  pd.to_timedelta(patient['age']*365+patient['age']//4, unit = 'D')\n",
    "        patient['year_of_birth'] = pd.DatetimeIndex(patient['birth_datetime']).year\n",
    "        patient['month_of_birth'] = pd.DatetimeIndex(patient['birth_datetime']).month\n",
    "        patient['day_of_birth'] = pd.DatetimeIndex(patient['birth_datetime']).day\n",
    "        patient['death_datetime'] = np.nan\n",
    "        patient['race_concept_id']=0\n",
    "        patient['ethnicity_concept_id']=0\n",
    "        patient['location_id']=np.nan\n",
    "        patient['provider_id']=np.nan\n",
    "        patient['care_site_id']=np.nan\n",
    "        patient['person_source_value']=patient.patientid.astype(int)\n",
    "        patient['gender_source_value']=patient['sex']\n",
    "        patient['gender_source_concept_id']=0\n",
    "        patient['race_source_value']=np.nan\n",
    "        patient['race_source_concept_id']=0\n",
    "        patient['ethnicity_source_value']=np.nan\n",
    "        patient['ethnicity_source_concept_id']=0\n",
    "        patient=patient[['person_id','gender_concept_id','year_of_birth','month_of_birth','day_of_birth',\n",
    "                         'birth_datetime','death_datetime','race_concept_id','ethnicity_concept_id',\n",
    "                        'location_id','provider_id','care_site_id','person_source_value','gender_source_value',\n",
    "                        'gender_source_concept_id','race_source_value','race_source_concept_id',\n",
    "                        'ethnicity_source_value','ethnicity_source_concept_id']]\n",
    "        self.convert_df2sql(patient, 'person')\n",
    "        self.person_upload_time=time.process_time() - start\n",
    "        #self.person_df=patient.copy()\n",
    "        print('\\tPerson upload successful!')\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Functionality: In this class you can translate the whole hiRID into Postgresql, feel free to modify it according to your needs\n",
      "\n",
      "    Variables:\n",
      "\n",
      "    \t*hirid_directory: Folder where your HiRID files uncompressed are located. Do not modify the file tree in order to work properly\n",
      "\n",
      "    \t*postgres_add: Connection string for the postgres database\n",
      "\n",
      "    \t*mapping_file: Directory path and file name for the Usagi's mapping folder, for more information about it check:\n",
      "https://www.ohdsi.org/web/wiki/doku.php?id=documentation:software:usagi\n",
      " \n",
      "    \t*max_group: Default value 250. Given that HiRID is divided in 250 groups the max group is the number of groups you want to upload\n",
      "\n",
      "    \t*sampling_mode: Allows the user to insert only a percentage of the data\n",
      "\n",
      "    Example:\t\n",
      "    \tuploadDb=UploadDB_Optimized('D:\\YourHiRIDFolderGoesHere\\',\"dbname='dbname' user='user' host='localhost' password='password' connect_timeout=1\",'D:\\DirectoryPath\\Vocabulary_translation.csv',1)\n",
      "\n",
      "    \tuploadDb.translate_upload()\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(UploadDB_Optimized.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning the translate and upload process...\n",
      "Process began at: 2020-08-20 19:47:26.237655\n",
      "\tTranslating and uploading Person table\n",
      "\tPerson upload successful!\n",
      "Translating in sample mode, expect less translated items\n",
      "\tTranslating item 1 of 250\n",
      "\t\tUploading observational period for group #0\n",
      "\t\tObservational period #0 done!\n",
      "\t\tUploading visit occurrence for group #0\n",
      "\t\tVisit occurrence #0 done!\n",
      "\t\tUploading measurements for group #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julio\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:158: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tMeasurement #0 done!\n",
      "\t\t330534 of 3307075 (9.99%) observations translated\n",
      "\t\tUploading visit pharmaceuticals for group #0\n",
      "\t\tPharmaceuticals #0 done!\n",
      "\t\t6353 of 72314 (8.79%) drugs records translated\n",
      "\tGroup #0 completed!\n",
      "Full Translation completed!\n",
      "330534 of 3307075 (9.99%) total observations translated\n",
      "6353 of 72314 (8.79%) drugs records translated\n",
      "336887 of 3379389 (9.97%) all the records were translated\n",
      "Process ended at: 2020-08-20 19:49:57.669251\n"
     ]
    }
   ],
   "source": [
    "uploadDb=UploadDB_Optimized('D:\\\\MIMICIII\\\\HiRID\\\\','postgresql://postgres:jp123456$@localhost:5432/omop_cdm3','D:\\\\MIMICIII\\\\HiRID\\\\Translation_13Aug.csv',1,sampling_mode=True)\n",
    "uploadDb.translate_upload()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
